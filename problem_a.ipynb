{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data science\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import multiprocessing\n",
    "# utils, tokenization and preprocessing\n",
    "from gensim import utils\n",
    "from random import shuffle\n",
    "import pymorphy2\n",
    "from scipy.special import expit\n",
    "from scipy.stats import logistic\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import codecs\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train_task1_latest.csv\", encoding='utf-8')\n",
    "test_df = pd.read_csv(\"data/sdsj_A_test.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>question</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1094</td>\n",
       "      <td>46273</td>\n",
       "      <td>В отличие от рыб, земноводные (амфибии) и прес...</td>\n",
       "      <td>С какого года Русское Царство перешло на летои...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7414</td>\n",
       "      <td>19164</td>\n",
       "      <td>В 1049 году Балдуину V удалось отнять у Герман...</td>\n",
       "      <td>Кто упомянул о его первых разногласиях со Штей...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6744</td>\n",
       "      <td>39767</td>\n",
       "      <td>Стремление достичь предельных значений ёмкости...</td>\n",
       "      <td>Как называется имеющая мировое значение эпоха ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7300</td>\n",
       "      <td>36318</td>\n",
       "      <td>Первый практически пригодный двухтактный газов...</td>\n",
       "      <td>Что усугублялось из-за международного давления...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7077</td>\n",
       "      <td>41534</td>\n",
       "      <td>Требуя от художника углубленного изучения изоб...</td>\n",
       "      <td>Какой характер носят пророчества Леонардо да В...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paragraph_id  question_id  \\\n",
       "0          1094        46273   \n",
       "1          7414        19164   \n",
       "2          6744        39767   \n",
       "3          7300        36318   \n",
       "4          7077        41534   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  В отличие от рыб, земноводные (амфибии) и прес...   \n",
       "1  В 1049 году Балдуину V удалось отнять у Герман...   \n",
       "2  Стремление достичь предельных значений ёмкости...   \n",
       "3  Первый практически пригодный двухтактный газов...   \n",
       "4  Требуя от художника углубленного изучения изоб...   \n",
       "\n",
       "                                            question  target  \n",
       "0  С какого года Русское Царство перешло на летои...     0.0  \n",
       "1  Кто упомянул о его первых разногласиях со Штей...     0.0  \n",
       "2  Как называется имеющая мировое значение эпоха ...     0.0  \n",
       "3  Что усугублялось из-за международного давления...     0.0  \n",
       "4  Какой характер носят пророчества Леонардо да В...     0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "cores = multiprocessing.cpu_count()\n",
    "num_partitions = 3 * cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Probably it is better not to tokenize questions\n",
    "def tokenize(string):\n",
    "    tokens = utils.simple_preprocess(string)\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        s = morph.parse(token)[0].normal_form\n",
    "        if len(s) > 1:\n",
    "            result.append(s)\n",
    "    return result\n",
    "\n",
    "def parallelize_df(df, func):\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    pool = multiprocessing.Pool(cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "def tokenize_df(df):\n",
    "    columns = df.columns\n",
    "    for col in columns:\n",
    "        if not col.endswith(\"id\"):\n",
    "            df[\"tokens\"] = df[col].apply(tokenize)\n",
    "    return df\n",
    "\n",
    "def tokenize_sent_df(df):\n",
    "    columns = df.columns\n",
    "    for col in columns:\n",
    "        if not col.endswith(\"id\"):\n",
    "            df[\"tokens\"] = df[col].apply(tokenize)\n",
    "            df[\"sent_tokens\"] = df[col].apply(lambda x: [tokenize(s) for s in tokenizer.tokenize(x)])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.tokenize.punkt.PunktParameters at 0x7f6644b567b8>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in trainings corpus\n",
    "plain_file = \"data/russian.plain\"\n",
    "text = codecs.open(plain_file, \"Ur\", \"utf-8\").read()\n",
    "\n",
    "# Train tokenizer\n",
    "tokenizer = PunktSentenceTokenizer()\n",
    "tokenizer.train(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_p = train_df[[\"paragraph_id\", \"paragraph\"]].drop_duplicates(subset=\"paragraph_id\")\n",
    "train_df_q = train_df[[\"question_id\", \"question\"]].drop_duplicates(subset=\"question_id\")\n",
    "test_df_p = test_df[[\"paragraph_id\", \"paragraph\"]].drop_duplicates(subset=\"paragraph_id\")\n",
    "test_df_q = test_df[[\"question_id\", \"question\"]].drop_duplicates(subset=\"question_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.01 s, sys: 2.11 s, total: 5.12 s\n",
      "Wall time: 29.2 s\n",
      "CPU times: user 190 ms, sys: 330 ms, total: 520 ms\n",
      "Wall time: 5.2 s\n",
      "CPU times: user 300 ms, sys: 290 ms, total: 590 ms\n",
      "Wall time: 5.51 s\n",
      "CPU times: user 410 ms, sys: 360 ms, total: 770 ms\n",
      "Wall time: 9.59 s\n"
     ]
    }
   ],
   "source": [
    "%time train_df_p = parallelize_df(train_df_p, tokenize_sent_df)\n",
    "%time train_df_q = parallelize_df(train_df_q, tokenize_df)\n",
    "%time test_df_p = parallelize_df(test_df_p, tokenize_sent_df)\n",
    "%time test_df_q = parallelize_df(test_df_q, tokenize_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_corpus_p = [TaggedDocument(row[\"tokens\"], [\"train_p_\" + str(row[\"paragraph_id\"])]) for i, row in train_df_p.iterrows()]\n",
    "train_corpus_q = [TaggedDocument(row[\"tokens\"], [\"train_q_\" + str(row[\"question_id\"])]) for i, row in train_df_q.iterrows()]\n",
    "test_corpus_p = [Taggeds_corpusDocument(row[\"tokens\"], [\"test_p_\" + str(row[\"paragraph_id\"])]) for i, row in test_df_p.iterrows()]\n",
    "test_corpus_q = [TaggedDocument(row[\"tokens\"], [\"test_q_\" + str(row[\"question_id\"])]) for i, row in test_df_q.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_corpus = [TaggedDocument(s, [\"s_\" + str(id(s))]) for p in train_df_p[\"sent_tokens\"].tolist() + test_df_p[\"sent_tokens\"].tolist() for s in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = train_corpus_p + train_corpus_q + test_corpus_p + test_corpus_q + s_corpus\n",
    "shuffle(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.4 s, sys: 850 ms, total: 10.2 s\n",
      "Wall time: 9.93 s\n"
     ]
    }
   ],
   "source": [
    "doc2vec = Doc2Vec(dm=0, dbow_words=1, size=300, window=150, min_count=5, iter=50, workers=cores) \n",
    "%time doc2vec.build_vocab(corpus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41min 49s, sys: 44.7 s, total: 42min 34s\n",
      "Wall time: 11min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26473864"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time doc2vec.train(corpus, total_examples=doc2vec.corpus_count, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# doc2vec.save(\"data/doc2vec\")\n",
    "# doc2vec = Doc2Vec.load(\"data/doc2vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dict for test dataset\n",
    "id2tokens = {}\n",
    "\n",
    "for i, row in test_df_p.iterrows():\n",
    "    _id = \"p-\" + str(row[\"paragraph_id\"])\n",
    "    id2tokens[_id] = row[\"tokens\"]\n",
    "\n",
    "for i, row in test_df_q.iterrows():\n",
    "    _id = \"q-\" + str(row[\"question_id\"])\n",
    "    id2tokens[_id] = row[\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_test_df(df):\n",
    "    df[\"prediction\"] =  df.apply(lambda row: doc2vec.docvecs.similarity(\"test_p_\" + str(row[\"paragraph_id\"]), \"test_q_\" + str(row[\"question_id\"])),axis=1)\n",
    "    return df\n",
    "\n",
    "def label_train_df(df):\n",
    "    df[\"prediction\"] =  df.apply(lambda row: doc2vec.docvecs.similarity(\"train_p_\" + str(row[\"paragraph_id\"]), \"train_q_\" + str(row[\"question_id\"])),axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.87 s, sys: 5.09 s, total: 9.96 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%time train_df = parallelize_df(train_df, label_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>question</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1094</td>\n",
       "      <td>46273</td>\n",
       "      <td>В отличие от рыб, земноводные (амфибии) и прес...</td>\n",
       "      <td>С какого года Русское Царство перешло на летои...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7414</td>\n",
       "      <td>19164</td>\n",
       "      <td>В 1049 году Балдуину V удалось отнять у Герман...</td>\n",
       "      <td>Кто упомянул о его первых разногласиях со Штей...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.228882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6744</td>\n",
       "      <td>39767</td>\n",
       "      <td>Стремление достичь предельных значений ёмкости...</td>\n",
       "      <td>Как называется имеющая мировое значение эпоха ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7300</td>\n",
       "      <td>36318</td>\n",
       "      <td>Первый практически пригодный двухтактный газов...</td>\n",
       "      <td>Что усугублялось из-за международного давления...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7077</td>\n",
       "      <td>41534</td>\n",
       "      <td>Требуя от художника углубленного изучения изоб...</td>\n",
       "      <td>Какой характер носят пророчества Леонардо да В...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.541730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paragraph_id  question_id  \\\n",
       "0          1094        46273   \n",
       "1          7414        19164   \n",
       "2          6744        39767   \n",
       "3          7300        36318   \n",
       "4          7077        41534   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  В отличие от рыб, земноводные (амфибии) и прес...   \n",
       "1  В 1049 году Балдуину V удалось отнять у Герман...   \n",
       "2  Стремление достичь предельных значений ёмкости...   \n",
       "3  Первый практически пригодный двухтактный газов...   \n",
       "4  Требуя от художника углубленного изучения изоб...   \n",
       "\n",
       "                                            question  target  prediction  \n",
       "0  С какого года Русское Царство перешло на летои...     0.0    0.215388  \n",
       "1  Кто упомянул о его первых разногласиях со Штей...     0.0    0.228882  \n",
       "2  Как называется имеющая мировое значение эпоха ...     0.0    0.111110  \n",
       "3  Что усугублялось из-за международного давления...     0.0    0.276297  \n",
       "4  Какой характер носят пророчества Леонардо да В...     0.0    0.541730  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96583871011112299"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(train_df[\"target\"].tolist(), train_df[\"prediction\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96460445215589641"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(train_df[\"target\"].tolist(), train_df[\"prediction\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.2 s, sys: 1.02 s, total: 3.22 s\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%time test_df = parallelize_df(test_df, label_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df[['paragraph_id', 'question_id', 'prediction']].to_csv(\"data/prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
